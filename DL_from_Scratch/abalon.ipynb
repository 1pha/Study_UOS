{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from keras import models, layers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex_1</th>\n",
       "      <th>sex_2</th>\n",
       "      <th>sex_3</th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.15</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.07</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.21</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex_1  sex_2  sex_3  length  diameter  height  whole_weight  \\\n",
       "0    0.0    0.0    1.0   0.455     0.365   0.095        0.5140   \n",
       "1    0.0    0.0    1.0   0.350     0.265   0.090        0.2255   \n",
       "2    1.0    0.0    0.0   0.530     0.420   0.135        0.6770   \n",
       "\n",
       "   shucked_weight  viscera_weight  shell_weight  rings  \n",
       "0          0.2245          0.1010          0.15   15.0  \n",
       "1          0.0995          0.0485          0.07    7.0  \n",
       "2          0.2565          0.1415          0.21    9.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset - abalone\n",
    "abalone_df = pd.read_csv('abalone_scikit_onehot_dataset.csv')\n",
    "abalone_df.head(3)\n",
    "len(abalone_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(abalone_df.iloc[:3600, :-1])\n",
    "x_test = np.array(abalone_df.iloc[3600:, :-1])\n",
    "target = np.array(abalone_df.iloc[:, -1])\n",
    "\n",
    "target_encoded = []\n",
    "for data in target:\n",
    "    target_encoded.append([0 if i!=data else 1 for i in range(29)])\n",
    "oe_train = np.array(target_encoded[:3600])\n",
    "oe_test = np.array(target_encoded[3600:])\n",
    "\n",
    "y_train = np.array(abalone_df.iloc[:3600, -1])\n",
    "y_test = np.array(abalone_df.iloc[3600:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3600 samples, validate on 577 samples\n",
      "Epoch 1/500\n",
      "3600/3600 [==============================] - 1s 146us/step - loss: 0.1780 - acc: 0.0178 - val_loss: 0.1143 - val_acc: 0.0485\n",
      "Epoch 2/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0874 - acc: 0.0578 - val_loss: 0.0586 - val_acc: 0.1196\n",
      "Epoch 3/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0505 - acc: 0.1253 - val_loss: 0.0402 - val_acc: 0.2305\n",
      "Epoch 4/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0381 - acc: 0.1917 - val_loss: 0.0342 - val_acc: 0.2288\n",
      "Epoch 5/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0338 - acc: 0.1925 - val_loss: 0.0319 - val_acc: 0.2340\n",
      "Epoch 6/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0320 - acc: 0.1936 - val_loss: 0.0308 - val_acc: 0.1802\n",
      "Epoch 7/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0312 - acc: 0.1861 - val_loss: 0.0301 - val_acc: 0.2322\n",
      "Epoch 8/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0308 - acc: 0.1900 - val_loss: 0.0298 - val_acc: 0.2236\n",
      "Epoch 9/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0305 - acc: 0.2039 - val_loss: 0.0296 - val_acc: 0.2270\n",
      "Epoch 10/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0303 - acc: 0.2069 - val_loss: 0.0293 - val_acc: 0.2496\n",
      "Epoch 11/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0302 - acc: 0.2147 - val_loss: 0.0292 - val_acc: 0.2305\n",
      "Epoch 12/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0301 - acc: 0.2272 - val_loss: 0.0292 - val_acc: 0.2426\n",
      "Epoch 13/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0300 - acc: 0.2206 - val_loss: 0.0293 - val_acc: 0.1872\n",
      "Epoch 14/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0300 - acc: 0.2039 - val_loss: 0.0288 - val_acc: 0.2426\n",
      "Epoch 15/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0299 - acc: 0.2231 - val_loss: 0.0290 - val_acc: 0.2444\n",
      "Epoch 16/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0298 - acc: 0.2278 - val_loss: 0.0287 - val_acc: 0.2513\n",
      "Epoch 17/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0298 - acc: 0.2217 - val_loss: 0.0288 - val_acc: 0.2548\n",
      "Epoch 18/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0298 - acc: 0.2303 - val_loss: 0.0291 - val_acc: 0.2617\n",
      "Epoch 19/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0298 - acc: 0.2311 - val_loss: 0.0287 - val_acc: 0.2582\n",
      "Epoch 20/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0297 - acc: 0.2286 - val_loss: 0.0287 - val_acc: 0.2496\n",
      "Epoch 21/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0297 - acc: 0.2333 - val_loss: 0.0287 - val_acc: 0.2652\n",
      "Epoch 22/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0297 - acc: 0.2286 - val_loss: 0.0288 - val_acc: 0.2721\n",
      "Epoch 23/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0296 - acc: 0.2328 - val_loss: 0.0287 - val_acc: 0.2374\n",
      "Epoch 24/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0296 - acc: 0.2314 - val_loss: 0.0286 - val_acc: 0.2444\n",
      "Epoch 25/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0296 - acc: 0.2303 - val_loss: 0.0286 - val_acc: 0.2444\n",
      "Epoch 26/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0295 - acc: 0.2317 - val_loss: 0.0284 - val_acc: 0.2652\n",
      "Epoch 27/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0295 - acc: 0.2342 - val_loss: 0.0289 - val_acc: 0.2530\n",
      "Epoch 28/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0295 - acc: 0.2331 - val_loss: 0.0285 - val_acc: 0.2652\n",
      "Epoch 29/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0295 - acc: 0.2300 - val_loss: 0.0285 - val_acc: 0.2478\n",
      "Epoch 30/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0294 - acc: 0.2400 - val_loss: 0.0286 - val_acc: 0.2461\n",
      "Epoch 31/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0294 - acc: 0.2406 - val_loss: 0.0283 - val_acc: 0.2738\n",
      "Epoch 32/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0294 - acc: 0.2353 - val_loss: 0.0284 - val_acc: 0.2704\n",
      "Epoch 33/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0294 - acc: 0.2369 - val_loss: 0.0286 - val_acc: 0.2704\n",
      "Epoch 34/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0294 - acc: 0.2375 - val_loss: 0.0284 - val_acc: 0.2704\n",
      "Epoch 35/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0293 - acc: 0.2383 - val_loss: 0.0282 - val_acc: 0.2634\n",
      "Epoch 36/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0293 - acc: 0.2486 - val_loss: 0.0285 - val_acc: 0.2704\n",
      "Epoch 37/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0293 - acc: 0.2353 - val_loss: 0.0283 - val_acc: 0.2756\n",
      "Epoch 38/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0293 - acc: 0.2419 - val_loss: 0.0281 - val_acc: 0.2652\n",
      "Epoch 39/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0293 - acc: 0.2375 - val_loss: 0.0282 - val_acc: 0.2825\n",
      "Epoch 40/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0293 - acc: 0.2364 - val_loss: 0.0283 - val_acc: 0.2825\n",
      "Epoch 41/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0292 - acc: 0.2467 - val_loss: 0.0282 - val_acc: 0.2617\n",
      "Epoch 42/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0292 - acc: 0.2439 - val_loss: 0.0285 - val_acc: 0.2322\n",
      "Epoch 43/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0292 - acc: 0.2411 - val_loss: 0.0281 - val_acc: 0.2894\n",
      "Epoch 44/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0292 - acc: 0.2447 - val_loss: 0.0281 - val_acc: 0.2426\n",
      "Epoch 45/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0292 - acc: 0.2356 - val_loss: 0.0280 - val_acc: 0.2530\n",
      "Epoch 46/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0291 - acc: 0.2414 - val_loss: 0.0281 - val_acc: 0.2634\n",
      "Epoch 47/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0291 - acc: 0.2428 - val_loss: 0.0280 - val_acc: 0.2825\n",
      "Epoch 48/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0291 - acc: 0.2500 - val_loss: 0.0279 - val_acc: 0.2946\n",
      "Epoch 49/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0291 - acc: 0.2453 - val_loss: 0.0280 - val_acc: 0.2686\n",
      "Epoch 50/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0291 - acc: 0.2481 - val_loss: 0.0279 - val_acc: 0.2773\n",
      "Epoch 51/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0291 - acc: 0.2497 - val_loss: 0.0282 - val_acc: 0.2721\n",
      "Epoch 52/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0291 - acc: 0.2481 - val_loss: 0.0281 - val_acc: 0.2825\n",
      "Epoch 53/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0291 - acc: 0.2425 - val_loss: 0.0281 - val_acc: 0.2860\n",
      "Epoch 54/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0290 - acc: 0.2483 - val_loss: 0.0280 - val_acc: 0.2756\n",
      "Epoch 55/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0290 - acc: 0.2522 - val_loss: 0.0280 - val_acc: 0.2600\n",
      "Epoch 56/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0290 - acc: 0.2503 - val_loss: 0.0280 - val_acc: 0.2721\n",
      "Epoch 57/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0290 - acc: 0.2564 - val_loss: 0.0279 - val_acc: 0.2894\n",
      "Epoch 58/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0290 - acc: 0.2456 - val_loss: 0.0282 - val_acc: 0.2825\n",
      "Epoch 59/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0290 - acc: 0.2539 - val_loss: 0.0278 - val_acc: 0.2929\n",
      "Epoch 60/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0290 - acc: 0.2517 - val_loss: 0.0279 - val_acc: 0.2704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0290 - acc: 0.2422 - val_loss: 0.0280 - val_acc: 0.2912\n",
      "Epoch 62/500\n",
      "3600/3600 [==============================] - 0s 4us/step - loss: 0.0289 - acc: 0.2528 - val_loss: 0.0279 - val_acc: 0.2912\n",
      "Epoch 63/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0289 - acc: 0.2583 - val_loss: 0.0280 - val_acc: 0.2808\n",
      "Epoch 64/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0289 - acc: 0.2547 - val_loss: 0.0277 - val_acc: 0.2912\n",
      "Epoch 65/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0289 - acc: 0.2533 - val_loss: 0.0278 - val_acc: 0.2946\n",
      "Epoch 66/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0289 - acc: 0.2514 - val_loss: 0.0279 - val_acc: 0.2721\n",
      "Epoch 67/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0289 - acc: 0.2508 - val_loss: 0.0279 - val_acc: 0.2669\n",
      "Epoch 68/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0289 - acc: 0.2500 - val_loss: 0.0278 - val_acc: 0.2721\n",
      "Epoch 69/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0288 - acc: 0.2492 - val_loss: 0.0279 - val_acc: 0.2964\n",
      "Epoch 70/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0289 - acc: 0.2528 - val_loss: 0.0279 - val_acc: 0.2773\n",
      "Epoch 71/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0289 - acc: 0.2544 - val_loss: 0.0277 - val_acc: 0.2877\n",
      "Epoch 72/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0288 - acc: 0.2550 - val_loss: 0.0277 - val_acc: 0.2860\n",
      "Epoch 73/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0288 - acc: 0.2528 - val_loss: 0.0278 - val_acc: 0.2929\n",
      "Epoch 74/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0288 - acc: 0.2483 - val_loss: 0.0277 - val_acc: 0.2808\n",
      "Epoch 75/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0288 - acc: 0.2481 - val_loss: 0.0279 - val_acc: 0.2842\n",
      "Epoch 76/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0288 - acc: 0.2506 - val_loss: 0.0277 - val_acc: 0.2877\n",
      "Epoch 77/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0288 - acc: 0.2544 - val_loss: 0.0279 - val_acc: 0.2912\n",
      "Epoch 78/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0288 - acc: 0.2581 - val_loss: 0.0280 - val_acc: 0.2582\n",
      "Epoch 79/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0288 - acc: 0.2547 - val_loss: 0.0277 - val_acc: 0.2877\n",
      "Epoch 80/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0288 - acc: 0.2539 - val_loss: 0.0278 - val_acc: 0.2860\n",
      "Epoch 81/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0287 - acc: 0.2575 - val_loss: 0.0277 - val_acc: 0.2929\n",
      "Epoch 82/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0287 - acc: 0.2508 - val_loss: 0.0277 - val_acc: 0.2842\n",
      "Epoch 83/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0287 - acc: 0.2553 - val_loss: 0.0278 - val_acc: 0.2704\n",
      "Epoch 84/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0287 - acc: 0.2544 - val_loss: 0.0278 - val_acc: 0.2860\n",
      "Epoch 85/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0287 - acc: 0.2544 - val_loss: 0.0276 - val_acc: 0.2825\n",
      "Epoch 86/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0287 - acc: 0.2525 - val_loss: 0.0278 - val_acc: 0.2565\n",
      "Epoch 87/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0287 - acc: 0.2578 - val_loss: 0.0278 - val_acc: 0.2981\n",
      "Epoch 88/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0287 - acc: 0.2503 - val_loss: 0.0278 - val_acc: 0.2738\n",
      "Epoch 89/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0287 - acc: 0.2533 - val_loss: 0.0276 - val_acc: 0.2894\n",
      "Epoch 90/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0287 - acc: 0.2519 - val_loss: 0.0277 - val_acc: 0.2929\n",
      "Epoch 91/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0287 - acc: 0.2569 - val_loss: 0.0276 - val_acc: 0.3085\n",
      "Epoch 92/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0286 - acc: 0.2567 - val_loss: 0.0277 - val_acc: 0.2825\n",
      "Epoch 93/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0286 - acc: 0.2558 - val_loss: 0.0275 - val_acc: 0.2998\n",
      "Epoch 94/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0286 - acc: 0.2556 - val_loss: 0.0277 - val_acc: 0.2808\n",
      "Epoch 95/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0286 - acc: 0.2564 - val_loss: 0.0276 - val_acc: 0.2842\n",
      "Epoch 96/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0286 - acc: 0.2578 - val_loss: 0.0277 - val_acc: 0.2981\n",
      "Epoch 97/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0286 - acc: 0.2631 - val_loss: 0.0276 - val_acc: 0.3206\n",
      "Epoch 98/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0286 - acc: 0.2556 - val_loss: 0.0278 - val_acc: 0.2790\n",
      "Epoch 99/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0286 - acc: 0.2575 - val_loss: 0.0276 - val_acc: 0.2842\n",
      "Epoch 100/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0286 - acc: 0.2644 - val_loss: 0.0277 - val_acc: 0.3137\n",
      "Epoch 101/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0286 - acc: 0.2575 - val_loss: 0.0274 - val_acc: 0.3068\n",
      "Epoch 102/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0286 - acc: 0.2536 - val_loss: 0.0276 - val_acc: 0.2877\n",
      "Epoch 103/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0286 - acc: 0.2539 - val_loss: 0.0275 - val_acc: 0.3033\n",
      "Epoch 104/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0286 - acc: 0.2608 - val_loss: 0.0275 - val_acc: 0.2964\n",
      "Epoch 105/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0285 - acc: 0.2567 - val_loss: 0.0275 - val_acc: 0.2981\n",
      "Epoch 106/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0285 - acc: 0.2622 - val_loss: 0.0275 - val_acc: 0.2756\n",
      "Epoch 107/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0285 - acc: 0.2542 - val_loss: 0.0279 - val_acc: 0.3033\n",
      "Epoch 108/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0285 - acc: 0.2614 - val_loss: 0.0274 - val_acc: 0.2964\n",
      "Epoch 109/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0285 - acc: 0.2631 - val_loss: 0.0274 - val_acc: 0.2929\n",
      "Epoch 110/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0285 - acc: 0.2539 - val_loss: 0.0276 - val_acc: 0.2894\n",
      "Epoch 111/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0285 - acc: 0.2578 - val_loss: 0.0275 - val_acc: 0.2704\n",
      "Epoch 112/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0285 - acc: 0.2589 - val_loss: 0.0274 - val_acc: 0.2808\n",
      "Epoch 113/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0285 - acc: 0.2667 - val_loss: 0.0275 - val_acc: 0.2912\n",
      "Epoch 114/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0285 - acc: 0.2639 - val_loss: 0.0276 - val_acc: 0.2808\n",
      "Epoch 115/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0285 - acc: 0.2622 - val_loss: 0.0273 - val_acc: 0.2981\n",
      "Epoch 116/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0285 - acc: 0.2650 - val_loss: 0.0276 - val_acc: 0.2946\n",
      "Epoch 117/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0285 - acc: 0.2678 - val_loss: 0.0274 - val_acc: 0.3033\n",
      "Epoch 118/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0285 - acc: 0.2631 - val_loss: 0.0273 - val_acc: 0.2877\n",
      "Epoch 119/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0285 - acc: 0.2511 - val_loss: 0.0273 - val_acc: 0.3085\n",
      "Epoch 120/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0285 - acc: 0.2592 - val_loss: 0.0274 - val_acc: 0.2790\n",
      "Epoch 121/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0284 - acc: 0.2667 - val_loss: 0.0275 - val_acc: 0.2860\n",
      "Epoch 122/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0284 - acc: 0.2683 - val_loss: 0.0275 - val_acc: 0.2912\n",
      "Epoch 123/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0284 - acc: 0.2619 - val_loss: 0.0276 - val_acc: 0.2860\n",
      "Epoch 124/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0284 - acc: 0.2592 - val_loss: 0.0273 - val_acc: 0.2912\n",
      "Epoch 125/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0284 - acc: 0.2631 - val_loss: 0.0274 - val_acc: 0.2929\n",
      "Epoch 126/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0284 - acc: 0.2606 - val_loss: 0.0274 - val_acc: 0.2825\n",
      "Epoch 127/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0284 - acc: 0.2608 - val_loss: 0.0275 - val_acc: 0.2808\n",
      "Epoch 128/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0284 - acc: 0.2628 - val_loss: 0.0274 - val_acc: 0.2912\n",
      "Epoch 129/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0284 - acc: 0.2597 - val_loss: 0.0272 - val_acc: 0.2946\n",
      "Epoch 130/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0284 - acc: 0.2647 - val_loss: 0.0274 - val_acc: 0.2912\n",
      "Epoch 131/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0284 - acc: 0.2631 - val_loss: 0.0274 - val_acc: 0.2652\n",
      "Epoch 132/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0284 - acc: 0.2650 - val_loss: 0.0274 - val_acc: 0.2808\n",
      "Epoch 133/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0284 - acc: 0.2692 - val_loss: 0.0273 - val_acc: 0.2998\n",
      "Epoch 134/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0284 - acc: 0.2650 - val_loss: 0.0278 - val_acc: 0.2790\n",
      "Epoch 135/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0284 - acc: 0.2614 - val_loss: 0.0274 - val_acc: 0.2981\n",
      "Epoch 136/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0284 - acc: 0.2633 - val_loss: 0.0274 - val_acc: 0.2808\n",
      "Epoch 137/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0284 - acc: 0.2622 - val_loss: 0.0274 - val_acc: 0.2929\n",
      "Epoch 138/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0283 - acc: 0.2697 - val_loss: 0.0273 - val_acc: 0.2860\n",
      "Epoch 139/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0284 - acc: 0.2675 - val_loss: 0.0273 - val_acc: 0.2894\n",
      "Epoch 140/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0284 - acc: 0.2628 - val_loss: 0.0276 - val_acc: 0.2912\n",
      "Epoch 141/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0283 - acc: 0.2694 - val_loss: 0.0275 - val_acc: 0.2790\n",
      "Epoch 142/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0283 - acc: 0.2606 - val_loss: 0.0274 - val_acc: 0.2998\n",
      "Epoch 143/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0283 - acc: 0.2686 - val_loss: 0.0275 - val_acc: 0.2929\n",
      "Epoch 144/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0283 - acc: 0.2675 - val_loss: 0.0273 - val_acc: 0.2981\n",
      "Epoch 145/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0283 - acc: 0.2672 - val_loss: 0.0274 - val_acc: 0.2842\n",
      "Epoch 146/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0283 - acc: 0.2697 - val_loss: 0.0274 - val_acc: 0.3016\n",
      "Epoch 147/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0283 - acc: 0.2667 - val_loss: 0.0277 - val_acc: 0.3154\n",
      "Epoch 148/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0283 - acc: 0.2628 - val_loss: 0.0276 - val_acc: 0.3102\n",
      "Epoch 149/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0283 - acc: 0.2597 - val_loss: 0.0274 - val_acc: 0.3016\n",
      "Epoch 150/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0283 - acc: 0.2672 - val_loss: 0.0274 - val_acc: 0.2946\n",
      "Epoch 151/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0283 - acc: 0.2647 - val_loss: 0.0273 - val_acc: 0.3102\n",
      "Epoch 152/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0283 - acc: 0.2711 - val_loss: 0.0273 - val_acc: 0.2825\n",
      "Epoch 153/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0283 - acc: 0.2592 - val_loss: 0.0274 - val_acc: 0.2929\n",
      "Epoch 154/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0283 - acc: 0.2672 - val_loss: 0.0273 - val_acc: 0.2946\n",
      "Epoch 155/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0283 - acc: 0.2617 - val_loss: 0.0274 - val_acc: 0.3033\n",
      "Epoch 156/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0283 - acc: 0.2658 - val_loss: 0.0273 - val_acc: 0.3033\n",
      "Epoch 157/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0283 - acc: 0.2678 - val_loss: 0.0274 - val_acc: 0.2946\n",
      "Epoch 158/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0283 - acc: 0.2653 - val_loss: 0.0272 - val_acc: 0.3050\n",
      "Epoch 159/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0283 - acc: 0.2672 - val_loss: 0.0273 - val_acc: 0.2981\n",
      "Epoch 160/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0283 - acc: 0.2714 - val_loss: 0.0272 - val_acc: 0.2912\n",
      "Epoch 161/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0283 - acc: 0.2703 - val_loss: 0.0272 - val_acc: 0.2981\n",
      "Epoch 162/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0283 - acc: 0.2656 - val_loss: 0.0274 - val_acc: 0.2981\n",
      "Epoch 163/500\n",
      "3600/3600 [==============================] - 0s 4us/step - loss: 0.0283 - acc: 0.2703 - val_loss: 0.0274 - val_acc: 0.2946\n",
      "Epoch 164/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0282 - acc: 0.2719 - val_loss: 0.0272 - val_acc: 0.3154\n",
      "Epoch 165/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0283 - acc: 0.2697 - val_loss: 0.0274 - val_acc: 0.3154\n",
      "Epoch 166/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0283 - acc: 0.2667 - val_loss: 0.0274 - val_acc: 0.3050\n",
      "Epoch 167/500\n",
      "3600/3600 [==============================] - 0s 4us/step - loss: 0.0282 - acc: 0.2644 - val_loss: 0.0273 - val_acc: 0.2964\n",
      "Epoch 168/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0282 - acc: 0.2728 - val_loss: 0.0273 - val_acc: 0.3016\n",
      "Epoch 169/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0282 - acc: 0.2681 - val_loss: 0.0273 - val_acc: 0.3102\n",
      "Epoch 170/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0282 - acc: 0.2683 - val_loss: 0.0273 - val_acc: 0.2894\n",
      "Epoch 171/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0282 - acc: 0.2683 - val_loss: 0.0273 - val_acc: 0.3154\n",
      "Epoch 172/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0282 - acc: 0.2658 - val_loss: 0.0273 - val_acc: 0.2998\n",
      "Epoch 173/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0282 - acc: 0.2639 - val_loss: 0.0271 - val_acc: 0.2981\n",
      "Epoch 174/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0282 - acc: 0.2728 - val_loss: 0.0273 - val_acc: 0.2929\n",
      "Epoch 175/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0282 - acc: 0.2694 - val_loss: 0.0274 - val_acc: 0.3120\n",
      "Epoch 176/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0282 - acc: 0.2653 - val_loss: 0.0274 - val_acc: 0.3137\n",
      "Epoch 177/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0282 - acc: 0.2731 - val_loss: 0.0272 - val_acc: 0.3241\n",
      "Epoch 178/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0282 - acc: 0.2719 - val_loss: 0.0272 - val_acc: 0.2929\n",
      "Epoch 179/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0282 - acc: 0.2750 - val_loss: 0.0272 - val_acc: 0.3085\n",
      "Epoch 180/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0282 - acc: 0.2728 - val_loss: 0.0272 - val_acc: 0.2912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0282 - acc: 0.2647 - val_loss: 0.0272 - val_acc: 0.2946\n",
      "Epoch 182/500\n",
      "3600/3600 [==============================] - 0s 4us/step - loss: 0.0282 - acc: 0.2708 - val_loss: 0.0275 - val_acc: 0.3224\n",
      "Epoch 183/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0282 - acc: 0.2706 - val_loss: 0.0272 - val_acc: 0.3085\n",
      "Epoch 184/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0282 - acc: 0.2681 - val_loss: 0.0273 - val_acc: 0.3137\n",
      "Epoch 185/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0282 - acc: 0.2722 - val_loss: 0.0272 - val_acc: 0.2981\n",
      "Epoch 186/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0282 - acc: 0.2767 - val_loss: 0.0272 - val_acc: 0.3154\n",
      "Epoch 187/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0282 - acc: 0.2636 - val_loss: 0.0272 - val_acc: 0.3033\n",
      "Epoch 188/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0282 - acc: 0.2750 - val_loss: 0.0271 - val_acc: 0.3224\n",
      "Epoch 189/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0282 - acc: 0.2711 - val_loss: 0.0274 - val_acc: 0.3033\n",
      "Epoch 190/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0282 - acc: 0.2764 - val_loss: 0.0273 - val_acc: 0.3120\n",
      "Epoch 191/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0282 - acc: 0.2753 - val_loss: 0.0272 - val_acc: 0.2877\n",
      "Epoch 192/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0282 - acc: 0.2714 - val_loss: 0.0274 - val_acc: 0.2998\n",
      "Epoch 193/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0282 - acc: 0.2717 - val_loss: 0.0273 - val_acc: 0.3206\n",
      "Epoch 194/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0282 - acc: 0.2706 - val_loss: 0.0274 - val_acc: 0.3068\n",
      "Epoch 195/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2758 - val_loss: 0.0271 - val_acc: 0.3050\n",
      "Epoch 196/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0282 - acc: 0.2744 - val_loss: 0.0272 - val_acc: 0.3102\n",
      "Epoch 197/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2761 - val_loss: 0.0271 - val_acc: 0.2998\n",
      "Epoch 198/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0282 - acc: 0.2703 - val_loss: 0.0271 - val_acc: 0.3120\n",
      "Epoch 199/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2694 - val_loss: 0.0274 - val_acc: 0.3102\n",
      "Epoch 200/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2761 - val_loss: 0.0272 - val_acc: 0.3120\n",
      "Epoch 201/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0282 - acc: 0.2756 - val_loss: 0.0272 - val_acc: 0.3137\n",
      "Epoch 202/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2739 - val_loss: 0.0272 - val_acc: 0.2998\n",
      "Epoch 203/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2736 - val_loss: 0.0273 - val_acc: 0.2912\n",
      "Epoch 204/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0281 - acc: 0.2717 - val_loss: 0.0272 - val_acc: 0.2981\n",
      "Epoch 205/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0281 - acc: 0.2728 - val_loss: 0.0273 - val_acc: 0.2946\n",
      "Epoch 206/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2742 - val_loss: 0.0271 - val_acc: 0.3050\n",
      "Epoch 207/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2739 - val_loss: 0.0273 - val_acc: 0.2998\n",
      "Epoch 208/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0281 - acc: 0.2714 - val_loss: 0.0272 - val_acc: 0.3154\n",
      "Epoch 209/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2811 - val_loss: 0.0271 - val_acc: 0.2912\n",
      "Epoch 210/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0281 - acc: 0.2767 - val_loss: 0.0272 - val_acc: 0.3102\n",
      "Epoch 211/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2742 - val_loss: 0.0273 - val_acc: 0.2894\n",
      "Epoch 212/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0281 - acc: 0.2783 - val_loss: 0.0272 - val_acc: 0.2981\n",
      "Epoch 213/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0281 - acc: 0.2786 - val_loss: 0.0273 - val_acc: 0.3172\n",
      "Epoch 214/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2750 - val_loss: 0.0272 - val_acc: 0.3016\n",
      "Epoch 215/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2764 - val_loss: 0.0272 - val_acc: 0.3085\n",
      "Epoch 216/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2731 - val_loss: 0.0272 - val_acc: 0.2998\n",
      "Epoch 217/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0281 - acc: 0.2767 - val_loss: 0.0273 - val_acc: 0.3102\n",
      "Epoch 218/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0281 - acc: 0.2767 - val_loss: 0.0272 - val_acc: 0.2946\n",
      "Epoch 219/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0281 - acc: 0.2800 - val_loss: 0.0272 - val_acc: 0.3102\n",
      "Epoch 220/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2689 - val_loss: 0.0271 - val_acc: 0.3154\n",
      "Epoch 221/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2725 - val_loss: 0.0272 - val_acc: 0.3016\n",
      "Epoch 222/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2786 - val_loss: 0.0272 - val_acc: 0.2929\n",
      "Epoch 223/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2778 - val_loss: 0.0271 - val_acc: 0.3120\n",
      "Epoch 224/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2803 - val_loss: 0.0273 - val_acc: 0.2981\n",
      "Epoch 225/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2753 - val_loss: 0.0272 - val_acc: 0.3050\n",
      "Epoch 226/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2739 - val_loss: 0.0271 - val_acc: 0.3085\n",
      "Epoch 227/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2733 - val_loss: 0.0272 - val_acc: 0.3068\n",
      "Epoch 228/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2781 - val_loss: 0.0271 - val_acc: 0.3033\n",
      "Epoch 229/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0281 - acc: 0.2806 - val_loss: 0.0271 - val_acc: 0.3085\n",
      "Epoch 230/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0281 - acc: 0.2789 - val_loss: 0.0272 - val_acc: 0.3102\n",
      "Epoch 231/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0281 - acc: 0.2772 - val_loss: 0.0273 - val_acc: 0.3085\n",
      "Epoch 232/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2786 - val_loss: 0.0271 - val_acc: 0.2998\n",
      "Epoch 233/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2800 - val_loss: 0.0270 - val_acc: 0.3085\n",
      "Epoch 234/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0281 - acc: 0.2764 - val_loss: 0.0272 - val_acc: 0.2998\n",
      "Epoch 235/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2733 - val_loss: 0.0270 - val_acc: 0.3224\n",
      "Epoch 236/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2761 - val_loss: 0.0272 - val_acc: 0.3050\n",
      "Epoch 237/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0281 - acc: 0.2731 - val_loss: 0.0273 - val_acc: 0.3033\n",
      "Epoch 238/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0280 - acc: 0.2803 - val_loss: 0.0270 - val_acc: 0.3033\n",
      "Epoch 239/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0280 - acc: 0.2758 - val_loss: 0.0270 - val_acc: 0.2964\n",
      "Epoch 240/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0280 - acc: 0.2825 - val_loss: 0.0272 - val_acc: 0.2860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0280 - acc: 0.2794 - val_loss: 0.0271 - val_acc: 0.3068\n",
      "Epoch 242/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0280 - acc: 0.2742 - val_loss: 0.0271 - val_acc: 0.3258\n",
      "Epoch 243/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0280 - acc: 0.2758 - val_loss: 0.0271 - val_acc: 0.3154\n",
      "Epoch 244/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0280 - acc: 0.2708 - val_loss: 0.0273 - val_acc: 0.3016\n",
      "Epoch 245/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0280 - acc: 0.2742 - val_loss: 0.0272 - val_acc: 0.3172\n",
      "Epoch 246/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0280 - acc: 0.2803 - val_loss: 0.0271 - val_acc: 0.3085\n",
      "Epoch 247/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0280 - acc: 0.2717 - val_loss: 0.0273 - val_acc: 0.3172\n",
      "Epoch 248/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0280 - acc: 0.2772 - val_loss: 0.0271 - val_acc: 0.3120\n",
      "Epoch 249/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0280 - acc: 0.2808 - val_loss: 0.0270 - val_acc: 0.3050\n",
      "Epoch 250/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0280 - acc: 0.2772 - val_loss: 0.0273 - val_acc: 0.3068\n",
      "Epoch 251/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0280 - acc: 0.2761 - val_loss: 0.0270 - val_acc: 0.3102\n",
      "Epoch 252/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0280 - acc: 0.2817 - val_loss: 0.0270 - val_acc: 0.3172\n",
      "Epoch 253/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0280 - acc: 0.2781 - val_loss: 0.0274 - val_acc: 0.3189\n",
      "Epoch 254/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0280 - acc: 0.2725 - val_loss: 0.0271 - val_acc: 0.3016\n",
      "Epoch 255/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0280 - acc: 0.2803 - val_loss: 0.0270 - val_acc: 0.3310\n",
      "Epoch 256/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0280 - acc: 0.2806 - val_loss: 0.0271 - val_acc: 0.3362\n",
      "Epoch 257/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0280 - acc: 0.2769 - val_loss: 0.0270 - val_acc: 0.3120\n",
      "Epoch 258/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0280 - acc: 0.2778 - val_loss: 0.0272 - val_acc: 0.3033\n",
      "Epoch 259/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0280 - acc: 0.2772 - val_loss: 0.0271 - val_acc: 0.3189\n",
      "Epoch 260/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0280 - acc: 0.2719 - val_loss: 0.0272 - val_acc: 0.3068\n",
      "Epoch 261/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0280 - acc: 0.2750 - val_loss: 0.0273 - val_acc: 0.3137\n",
      "Epoch 262/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0280 - acc: 0.2769 - val_loss: 0.0271 - val_acc: 0.3224\n",
      "Epoch 263/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0280 - acc: 0.2811 - val_loss: 0.0270 - val_acc: 0.3224\n",
      "Epoch 264/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0280 - acc: 0.2794 - val_loss: 0.0273 - val_acc: 0.3137\n",
      "Epoch 265/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0280 - acc: 0.2744 - val_loss: 0.0271 - val_acc: 0.3172\n",
      "Epoch 266/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0280 - acc: 0.2800 - val_loss: 0.0270 - val_acc: 0.3137\n",
      "Epoch 267/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0280 - acc: 0.2789 - val_loss: 0.0270 - val_acc: 0.3206\n",
      "Epoch 268/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0280 - acc: 0.2761 - val_loss: 0.0271 - val_acc: 0.3241\n",
      "Epoch 269/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0280 - acc: 0.2767 - val_loss: 0.0271 - val_acc: 0.3154\n",
      "Epoch 270/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0280 - acc: 0.2764 - val_loss: 0.0274 - val_acc: 0.3120\n",
      "Epoch 271/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0280 - acc: 0.2736 - val_loss: 0.0271 - val_acc: 0.2981\n",
      "Epoch 272/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0280 - acc: 0.2844 - val_loss: 0.0273 - val_acc: 0.3050\n",
      "Epoch 273/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0280 - acc: 0.2817 - val_loss: 0.0270 - val_acc: 0.3293\n",
      "Epoch 274/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0280 - acc: 0.2739 - val_loss: 0.0270 - val_acc: 0.3050\n",
      "Epoch 275/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0280 - acc: 0.2822 - val_loss: 0.0272 - val_acc: 0.3033\n",
      "Epoch 276/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0280 - acc: 0.2819 - val_loss: 0.0271 - val_acc: 0.3137\n",
      "Epoch 277/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0280 - acc: 0.2828 - val_loss: 0.0270 - val_acc: 0.3154\n",
      "Epoch 278/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0280 - acc: 0.2717 - val_loss: 0.0271 - val_acc: 0.3085\n",
      "Epoch 279/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2806 - val_loss: 0.0270 - val_acc: 0.3085\n",
      "Epoch 280/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0280 - acc: 0.2819 - val_loss: 0.0273 - val_acc: 0.3085\n",
      "Epoch 281/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0280 - acc: 0.2786 - val_loss: 0.0270 - val_acc: 0.3224\n",
      "Epoch 282/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0279 - acc: 0.2783 - val_loss: 0.0275 - val_acc: 0.3102\n",
      "Epoch 283/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0280 - acc: 0.2800 - val_loss: 0.0272 - val_acc: 0.3206\n",
      "Epoch 284/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2806 - val_loss: 0.0271 - val_acc: 0.3137\n",
      "Epoch 285/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2750 - val_loss: 0.0272 - val_acc: 0.3172\n",
      "Epoch 286/500\n",
      "3600/3600 [==============================] - 0s 4us/step - loss: 0.0280 - acc: 0.2817 - val_loss: 0.0271 - val_acc: 0.3137\n",
      "Epoch 287/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2822 - val_loss: 0.0270 - val_acc: 0.3033\n",
      "Epoch 288/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0279 - acc: 0.2806 - val_loss: 0.0270 - val_acc: 0.3068\n",
      "Epoch 289/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2819 - val_loss: 0.0271 - val_acc: 0.3068\n",
      "Epoch 290/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0279 - acc: 0.2792 - val_loss: 0.0272 - val_acc: 0.3224\n",
      "Epoch 291/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0279 - acc: 0.2839 - val_loss: 0.0271 - val_acc: 0.3102\n",
      "Epoch 292/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2811 - val_loss: 0.0269 - val_acc: 0.2998\n",
      "Epoch 293/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2775 - val_loss: 0.0274 - val_acc: 0.3085\n",
      "Epoch 294/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2794 - val_loss: 0.0272 - val_acc: 0.3050\n",
      "Epoch 295/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0279 - acc: 0.2778 - val_loss: 0.0270 - val_acc: 0.3172\n",
      "Epoch 296/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0279 - acc: 0.2778 - val_loss: 0.0270 - val_acc: 0.3258\n",
      "Epoch 297/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2797 - val_loss: 0.0270 - val_acc: 0.3154\n",
      "Epoch 298/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0279 - acc: 0.2794 - val_loss: 0.0270 - val_acc: 0.3189\n",
      "Epoch 299/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2869 - val_loss: 0.0270 - val_acc: 0.3154\n",
      "Epoch 300/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2794 - val_loss: 0.0269 - val_acc: 0.3120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0279 - acc: 0.2758 - val_loss: 0.0271 - val_acc: 0.3276\n",
      "Epoch 302/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0279 - acc: 0.2819 - val_loss: 0.0272 - val_acc: 0.3172\n",
      "Epoch 303/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2758 - val_loss: 0.0271 - val_acc: 0.3154\n",
      "Epoch 304/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2764 - val_loss: 0.0272 - val_acc: 0.3224\n",
      "Epoch 305/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2828 - val_loss: 0.0271 - val_acc: 0.3068\n",
      "Epoch 306/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2714 - val_loss: 0.0270 - val_acc: 0.3258\n",
      "Epoch 307/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2847 - val_loss: 0.0271 - val_acc: 0.3085\n",
      "Epoch 308/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2794 - val_loss: 0.0272 - val_acc: 0.3085\n",
      "Epoch 309/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2811 - val_loss: 0.0269 - val_acc: 0.3050\n",
      "Epoch 310/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2839 - val_loss: 0.0272 - val_acc: 0.3172\n",
      "Epoch 311/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2831 - val_loss: 0.0272 - val_acc: 0.3068\n",
      "Epoch 312/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2786 - val_loss: 0.0269 - val_acc: 0.3224\n",
      "Epoch 313/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2803 - val_loss: 0.0270 - val_acc: 0.3276\n",
      "Epoch 314/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0279 - acc: 0.2856 - val_loss: 0.0270 - val_acc: 0.3068\n",
      "Epoch 315/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0279 - acc: 0.2800 - val_loss: 0.0270 - val_acc: 0.3050\n",
      "Epoch 316/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0279 - acc: 0.2819 - val_loss: 0.0270 - val_acc: 0.3380\n",
      "Epoch 317/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2897 - val_loss: 0.0269 - val_acc: 0.3224\n",
      "Epoch 318/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2867 - val_loss: 0.0270 - val_acc: 0.3137\n",
      "Epoch 319/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2778 - val_loss: 0.0271 - val_acc: 0.3189\n",
      "Epoch 320/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2819 - val_loss: 0.0270 - val_acc: 0.3102\n",
      "Epoch 321/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2850 - val_loss: 0.0270 - val_acc: 0.3120\n",
      "Epoch 322/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2817 - val_loss: 0.0269 - val_acc: 0.3068\n",
      "Epoch 323/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2808 - val_loss: 0.0270 - val_acc: 0.3050\n",
      "Epoch 324/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0279 - acc: 0.2853 - val_loss: 0.0269 - val_acc: 0.3085\n",
      "Epoch 325/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0279 - acc: 0.2806 - val_loss: 0.0268 - val_acc: 0.3154\n",
      "Epoch 326/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0279 - acc: 0.2847 - val_loss: 0.0272 - val_acc: 0.3050\n",
      "Epoch 327/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0279 - acc: 0.2839 - val_loss: 0.0270 - val_acc: 0.3050\n",
      "Epoch 328/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2783 - val_loss: 0.0270 - val_acc: 0.3137\n",
      "Epoch 329/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2858 - val_loss: 0.0272 - val_acc: 0.3102\n",
      "Epoch 330/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2786 - val_loss: 0.0272 - val_acc: 0.3050\n",
      "Epoch 331/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0279 - acc: 0.2825 - val_loss: 0.0269 - val_acc: 0.3293\n",
      "Epoch 332/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0279 - acc: 0.2819 - val_loss: 0.0270 - val_acc: 0.3016\n",
      "Epoch 333/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2828 - val_loss: 0.0272 - val_acc: 0.3137\n",
      "Epoch 334/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2822 - val_loss: 0.0272 - val_acc: 0.3033\n",
      "Epoch 335/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2825 - val_loss: 0.0271 - val_acc: 0.3206\n",
      "Epoch 336/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2797 - val_loss: 0.0270 - val_acc: 0.3050\n",
      "Epoch 337/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0278 - acc: 0.2839 - val_loss: 0.0270 - val_acc: 0.3120\n",
      "Epoch 338/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0278 - acc: 0.2800 - val_loss: 0.0270 - val_acc: 0.3102\n",
      "Epoch 339/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0278 - acc: 0.2753 - val_loss: 0.0269 - val_acc: 0.3137\n",
      "Epoch 340/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0279 - acc: 0.2831 - val_loss: 0.0269 - val_acc: 0.3189\n",
      "Epoch 341/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2803 - val_loss: 0.0270 - val_acc: 0.3068\n",
      "Epoch 342/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0278 - acc: 0.2800 - val_loss: 0.0271 - val_acc: 0.3137\n",
      "Epoch 343/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0278 - acc: 0.2858 - val_loss: 0.0269 - val_acc: 0.3224\n",
      "Epoch 344/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0278 - acc: 0.2825 - val_loss: 0.0270 - val_acc: 0.3068\n",
      "Epoch 345/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0278 - acc: 0.2778 - val_loss: 0.0271 - val_acc: 0.3137\n",
      "Epoch 346/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2875 - val_loss: 0.0271 - val_acc: 0.3206\n",
      "Epoch 347/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2800 - val_loss: 0.0270 - val_acc: 0.3137\n",
      "Epoch 348/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2794 - val_loss: 0.0268 - val_acc: 0.3102\n",
      "Epoch 349/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2781 - val_loss: 0.0270 - val_acc: 0.3016\n",
      "Epoch 350/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2806 - val_loss: 0.0272 - val_acc: 0.3206\n",
      "Epoch 351/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0278 - acc: 0.2783 - val_loss: 0.0271 - val_acc: 0.3172\n",
      "Epoch 352/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0278 - acc: 0.2872 - val_loss: 0.0271 - val_acc: 0.3137\n",
      "Epoch 353/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0278 - acc: 0.2797 - val_loss: 0.0270 - val_acc: 0.3206\n",
      "Epoch 354/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0278 - acc: 0.2847 - val_loss: 0.0270 - val_acc: 0.3189\n",
      "Epoch 355/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0278 - acc: 0.2822 - val_loss: 0.0271 - val_acc: 0.3102\n",
      "Epoch 356/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2850 - val_loss: 0.0272 - val_acc: 0.3033\n",
      "Epoch 357/500\n",
      "3600/3600 [==============================] - 0s 4us/step - loss: 0.0278 - acc: 0.2756 - val_loss: 0.0269 - val_acc: 0.3206\n",
      "Epoch 358/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2856 - val_loss: 0.0270 - val_acc: 0.3224\n",
      "Epoch 359/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2881 - val_loss: 0.0271 - val_acc: 0.3033\n",
      "Epoch 360/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2783 - val_loss: 0.0272 - val_acc: 0.3154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2822 - val_loss: 0.0270 - val_acc: 0.3154\n",
      "Epoch 362/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2833 - val_loss: 0.0270 - val_acc: 0.3068\n",
      "Epoch 363/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2878 - val_loss: 0.0271 - val_acc: 0.3137\n",
      "Epoch 364/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2814 - val_loss: 0.0272 - val_acc: 0.3085\n",
      "Epoch 365/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0278 - acc: 0.2825 - val_loss: 0.0272 - val_acc: 0.3102\n",
      "Epoch 366/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2783 - val_loss: 0.0271 - val_acc: 0.3068\n",
      "Epoch 367/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2794 - val_loss: 0.0271 - val_acc: 0.3137\n",
      "Epoch 368/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2811 - val_loss: 0.0270 - val_acc: 0.3085\n",
      "Epoch 369/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2850 - val_loss: 0.0270 - val_acc: 0.3241\n",
      "Epoch 370/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2886 - val_loss: 0.0270 - val_acc: 0.3154\n",
      "Epoch 371/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2850 - val_loss: 0.0270 - val_acc: 0.3224\n",
      "Epoch 372/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2858 - val_loss: 0.0270 - val_acc: 0.3120\n",
      "Epoch 373/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2864 - val_loss: 0.0268 - val_acc: 0.3016\n",
      "Epoch 374/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2878 - val_loss: 0.0271 - val_acc: 0.3085\n",
      "Epoch 375/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2867 - val_loss: 0.0271 - val_acc: 0.3137\n",
      "Epoch 376/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0278 - acc: 0.2800 - val_loss: 0.0271 - val_acc: 0.3224\n",
      "Epoch 377/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0278 - acc: 0.2814 - val_loss: 0.0272 - val_acc: 0.3016\n",
      "Epoch 378/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0278 - acc: 0.2861 - val_loss: 0.0269 - val_acc: 0.3206\n",
      "Epoch 379/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0278 - acc: 0.2828 - val_loss: 0.0269 - val_acc: 0.3293\n",
      "Epoch 380/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2822 - val_loss: 0.0269 - val_acc: 0.3137\n",
      "Epoch 381/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2872 - val_loss: 0.0269 - val_acc: 0.3172\n",
      "Epoch 382/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2797 - val_loss: 0.0270 - val_acc: 0.3050\n",
      "Epoch 383/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2769 - val_loss: 0.0269 - val_acc: 0.3120\n",
      "Epoch 384/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2814 - val_loss: 0.0269 - val_acc: 0.3276\n",
      "Epoch 385/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2778 - val_loss: 0.0269 - val_acc: 0.3120\n",
      "Epoch 386/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2817 - val_loss: 0.0269 - val_acc: 0.3293\n",
      "Epoch 387/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2867 - val_loss: 0.0269 - val_acc: 0.3033\n",
      "Epoch 388/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0278 - acc: 0.2864 - val_loss: 0.0269 - val_acc: 0.3189\n",
      "Epoch 389/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0278 - acc: 0.2797 - val_loss: 0.0270 - val_acc: 0.3050\n",
      "Epoch 390/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0278 - acc: 0.2875 - val_loss: 0.0270 - val_acc: 0.3154\n",
      "Epoch 391/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2756 - val_loss: 0.0270 - val_acc: 0.3224\n",
      "Epoch 392/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2847 - val_loss: 0.0271 - val_acc: 0.3154\n",
      "Epoch 393/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2875 - val_loss: 0.0270 - val_acc: 0.3206\n",
      "Epoch 394/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0278 - acc: 0.2847 - val_loss: 0.0269 - val_acc: 0.3258\n",
      "Epoch 395/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0278 - acc: 0.2842 - val_loss: 0.0269 - val_acc: 0.3206\n",
      "Epoch 396/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2808 - val_loss: 0.0271 - val_acc: 0.3258\n",
      "Epoch 397/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2864 - val_loss: 0.0271 - val_acc: 0.2998\n",
      "Epoch 398/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2875 - val_loss: 0.0270 - val_acc: 0.3172\n",
      "Epoch 399/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2853 - val_loss: 0.0272 - val_acc: 0.3085\n",
      "Epoch 400/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2878 - val_loss: 0.0270 - val_acc: 0.3102\n",
      "Epoch 401/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2900 - val_loss: 0.0271 - val_acc: 0.3154\n",
      "Epoch 402/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2869 - val_loss: 0.0270 - val_acc: 0.3085\n",
      "Epoch 403/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2847 - val_loss: 0.0271 - val_acc: 0.3154\n",
      "Epoch 404/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0278 - acc: 0.2839 - val_loss: 0.0270 - val_acc: 0.3172\n",
      "Epoch 405/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2883 - val_loss: 0.0272 - val_acc: 0.3033\n",
      "Epoch 406/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0278 - acc: 0.2803 - val_loss: 0.0269 - val_acc: 0.3102\n",
      "Epoch 407/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2914 - val_loss: 0.0268 - val_acc: 0.3172\n",
      "Epoch 408/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2822 - val_loss: 0.0270 - val_acc: 0.3137\n",
      "Epoch 409/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2811 - val_loss: 0.0271 - val_acc: 0.3137\n",
      "Epoch 410/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2803 - val_loss: 0.0269 - val_acc: 0.3328\n",
      "Epoch 411/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.2808 - val_loss: 0.0270 - val_acc: 0.3224\n",
      "Epoch 412/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2864 - val_loss: 0.0272 - val_acc: 0.3016\n",
      "Epoch 413/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2911 - val_loss: 0.0270 - val_acc: 0.3137\n",
      "Epoch 414/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2783 - val_loss: 0.0271 - val_acc: 0.3050\n",
      "Epoch 415/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0277 - acc: 0.2819 - val_loss: 0.0268 - val_acc: 0.3120\n",
      "Epoch 416/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2867 - val_loss: 0.0269 - val_acc: 0.3241\n",
      "Epoch 417/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2850 - val_loss: 0.0270 - val_acc: 0.3033\n",
      "Epoch 418/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2828 - val_loss: 0.0271 - val_acc: 0.3102\n",
      "Epoch 419/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2856 - val_loss: 0.0270 - val_acc: 0.2964\n",
      "Epoch 420/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2847 - val_loss: 0.0268 - val_acc: 0.3137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2856 - val_loss: 0.0270 - val_acc: 0.3241\n",
      "Epoch 422/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2878 - val_loss: 0.0268 - val_acc: 0.3102\n",
      "Epoch 423/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2936 - val_loss: 0.0271 - val_acc: 0.3137\n",
      "Epoch 424/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2911 - val_loss: 0.0270 - val_acc: 0.3276\n",
      "Epoch 425/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2842 - val_loss: 0.0269 - val_acc: 0.3172\n",
      "Epoch 426/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2828 - val_loss: 0.0268 - val_acc: 0.3137\n",
      "Epoch 427/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2833 - val_loss: 0.0269 - val_acc: 0.3258\n",
      "Epoch 428/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2797 - val_loss: 0.0271 - val_acc: 0.3154\n",
      "Epoch 429/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2778 - val_loss: 0.0271 - val_acc: 0.3120\n",
      "Epoch 430/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2850 - val_loss: 0.0271 - val_acc: 0.3137\n",
      "Epoch 431/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2842 - val_loss: 0.0268 - val_acc: 0.3102\n",
      "Epoch 432/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2844 - val_loss: 0.0268 - val_acc: 0.3085\n",
      "Epoch 433/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2886 - val_loss: 0.0268 - val_acc: 0.3172\n",
      "Epoch 434/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2806 - val_loss: 0.0270 - val_acc: 0.3137\n",
      "Epoch 435/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2867 - val_loss: 0.0270 - val_acc: 0.3120\n",
      "Epoch 436/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2833 - val_loss: 0.0269 - val_acc: 0.3137\n",
      "Epoch 437/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2878 - val_loss: 0.0270 - val_acc: 0.3016\n",
      "Epoch 438/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0277 - acc: 0.2806 - val_loss: 0.0269 - val_acc: 0.3120\n",
      "Epoch 439/500\n",
      "3600/3600 [==============================] - 0s 7us/step - loss: 0.0277 - acc: 0.2858 - val_loss: 0.0269 - val_acc: 0.3068\n",
      "Epoch 440/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2886 - val_loss: 0.0269 - val_acc: 0.3154\n",
      "Epoch 441/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2894 - val_loss: 0.0268 - val_acc: 0.3189\n",
      "Epoch 442/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2903 - val_loss: 0.0270 - val_acc: 0.3068\n",
      "Epoch 443/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2881 - val_loss: 0.0271 - val_acc: 0.3085\n",
      "Epoch 444/500\n",
      "3600/3600 [==============================] - 0s 8us/step - loss: 0.0277 - acc: 0.2811 - val_loss: 0.0270 - val_acc: 0.3258\n",
      "Epoch 445/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2853 - val_loss: 0.0271 - val_acc: 0.3050\n",
      "Epoch 446/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2894 - val_loss: 0.0270 - val_acc: 0.3172\n",
      "Epoch 447/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2903 - val_loss: 0.0269 - val_acc: 0.3189\n",
      "Epoch 448/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2861 - val_loss: 0.0269 - val_acc: 0.3345\n",
      "Epoch 449/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2886 - val_loss: 0.0271 - val_acc: 0.3258\n",
      "Epoch 450/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2850 - val_loss: 0.0270 - val_acc: 0.3102\n",
      "Epoch 451/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2872 - val_loss: 0.0270 - val_acc: 0.3224\n",
      "Epoch 452/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2839 - val_loss: 0.0270 - val_acc: 0.3050\n",
      "Epoch 453/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2878 - val_loss: 0.0271 - val_acc: 0.3189\n",
      "Epoch 454/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2925 - val_loss: 0.0269 - val_acc: 0.3258\n",
      "Epoch 455/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2964 - val_loss: 0.0270 - val_acc: 0.3137\n",
      "Epoch 456/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2894 - val_loss: 0.0269 - val_acc: 0.3258\n",
      "Epoch 457/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2867 - val_loss: 0.0269 - val_acc: 0.3189\n",
      "Epoch 458/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2906 - val_loss: 0.0269 - val_acc: 0.3085\n",
      "Epoch 459/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2867 - val_loss: 0.0270 - val_acc: 0.3172\n",
      "Epoch 460/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2869 - val_loss: 0.0269 - val_acc: 0.3258\n",
      "Epoch 461/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2886 - val_loss: 0.0270 - val_acc: 0.3189\n",
      "Epoch 462/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2831 - val_loss: 0.0271 - val_acc: 0.2912\n",
      "Epoch 463/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2942 - val_loss: 0.0271 - val_acc: 0.3276\n",
      "Epoch 464/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2883 - val_loss: 0.0270 - val_acc: 0.3102\n",
      "Epoch 465/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2919 - val_loss: 0.0270 - val_acc: 0.3137\n",
      "Epoch 466/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2822 - val_loss: 0.0270 - val_acc: 0.3293\n",
      "Epoch 467/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2819 - val_loss: 0.0269 - val_acc: 0.3206\n",
      "Epoch 468/500\n",
      "3600/3600 [==============================] - 0s 4us/step - loss: 0.0277 - acc: 0.2892 - val_loss: 0.0270 - val_acc: 0.3033\n",
      "Epoch 469/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2889 - val_loss: 0.0269 - val_acc: 0.3120\n",
      "Epoch 470/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2875 - val_loss: 0.0270 - val_acc: 0.3085\n",
      "Epoch 471/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2872 - val_loss: 0.0269 - val_acc: 0.2998\n",
      "Epoch 472/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2861 - val_loss: 0.0269 - val_acc: 0.3241\n",
      "Epoch 473/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2942 - val_loss: 0.0270 - val_acc: 0.3206\n",
      "Epoch 474/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2844 - val_loss: 0.0268 - val_acc: 0.3241\n",
      "Epoch 475/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2914 - val_loss: 0.0271 - val_acc: 0.3016\n",
      "Epoch 476/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2914 - val_loss: 0.0269 - val_acc: 0.3224\n",
      "Epoch 477/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2906 - val_loss: 0.0268 - val_acc: 0.3085\n",
      "Epoch 478/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2883 - val_loss: 0.0270 - val_acc: 0.3189\n",
      "Epoch 479/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2883 - val_loss: 0.0269 - val_acc: 0.3172\n",
      "Epoch 480/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2917 - val_loss: 0.0268 - val_acc: 0.3241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2894 - val_loss: 0.0270 - val_acc: 0.3102\n",
      "Epoch 482/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2842 - val_loss: 0.0269 - val_acc: 0.3189\n",
      "Epoch 483/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2908 - val_loss: 0.0268 - val_acc: 0.3206\n",
      "Epoch 484/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2908 - val_loss: 0.0269 - val_acc: 0.3120\n",
      "Epoch 485/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2889 - val_loss: 0.0269 - val_acc: 0.3102\n",
      "Epoch 486/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2956 - val_loss: 0.0269 - val_acc: 0.3154\n",
      "Epoch 487/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2925 - val_loss: 0.0270 - val_acc: 0.3172\n",
      "Epoch 488/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2919 - val_loss: 0.0271 - val_acc: 0.3137\n",
      "Epoch 489/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2867 - val_loss: 0.0270 - val_acc: 0.3310\n",
      "Epoch 490/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2897 - val_loss: 0.0270 - val_acc: 0.3224\n",
      "Epoch 491/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2847 - val_loss: 0.0271 - val_acc: 0.3189\n",
      "Epoch 492/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2842 - val_loss: 0.0268 - val_acc: 0.3310\n",
      "Epoch 493/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2872 - val_loss: 0.0269 - val_acc: 0.3276\n",
      "Epoch 494/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2853 - val_loss: 0.0269 - val_acc: 0.3102\n",
      "Epoch 495/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2883 - val_loss: 0.0271 - val_acc: 0.3033\n",
      "Epoch 496/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2861 - val_loss: 0.0270 - val_acc: 0.3189\n",
      "Epoch 497/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2936 - val_loss: 0.0272 - val_acc: 0.3172\n",
      "Epoch 498/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2839 - val_loss: 0.0269 - val_acc: 0.3172\n",
      "Epoch 499/500\n",
      "3600/3600 [==============================] - 0s 5us/step - loss: 0.0277 - acc: 0.2917 - val_loss: 0.0270 - val_acc: 0.3085\n",
      "Epoch 500/500\n",
      "3600/3600 [==============================] - 0s 6us/step - loss: 0.0277 - acc: 0.2842 - val_loss: 0.0269 - val_acc: 0.3293\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(200, activation='relu', input_shape=(10,)))\n",
    "#model.add(layers.Dense(15, activation='relu'))\n",
    "model.add(layers.Dense(29, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='mse',\n",
    "             metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, epochs=500, batch_size=256, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18183e3a940>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18183e21160>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training and Validation loss')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x18183e3afd0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18183ea5ac8>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18183e84400>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training and Validation Accuracy')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577/577 [==============================] - 0s 14us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02689590880669899, 0.3292894280762565]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
